"""
Stress tests para validar performance em escala.

Testa processamento de 100, 500, 1000 guias.
Meta: > 500 guias/hora, < 4GB RAM
"""
import pytest
import time
import psutil
import os
from pathlib import Path

# Importar gerador
import sys
sys.path.insert(0, str(Path(__file__).parent))
from generate_test_xmls import generate_test_batch


def get_memory_usage_mb():
    """Retorna uso de memÃ³ria em MB"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024


@pytest.mark.slow
@pytest.mark.skipif(not os.getenv('RUN_STRESS_TESTS'), reason="Stress tests desabilitados por padrÃ£o")
class TestStressPerformance:
    """Testes de stress e performance"""
    
    def test_100_guias_benchmark(self, rule_engine, tmp_path):
        """
        Processa 100 guias e mede performance baseline.
        
        Meta: < 3 minutos (33 guias/min = 2000/hora)
        """
        from src.business.processing.safe_batch_processor import process_batch
        
        # Gerar XMLs
        print("\nğŸ”§ Gerando 100 XMLs...")
        files = generate_test_batch(
            count=100,
            output_dir=str(tmp_path / "batch_100"),
            error_rate=0.0
        )
        
        # Medir memÃ³ria inicial
        mem_start = get_memory_usage_mb()
        
        # Processar
        print("\nğŸš€ Processando lote...")
        start = time.time()
        summary = process_batch(files, rule_engine)
        duration = time.time() - start
        
        # Medir memÃ³ria final
        mem_end = get_memory_usage_mb()
        mem_delta = mem_end - mem_start
        
        # MÃ©tricas
        throughput_per_hour = (summary['success'] / duration) * 3600
        
        # RelatÃ³rio
        print(f"\nğŸ“Š RESULTADOS - 100 Guias:")
        print(f"  âœ… Sucesso: {summary['success']}/{summary['total']}")
        print(f"  â±ï¸  Tempo: {duration:.1f}s ({duration/60:.1f} min)")
        print(f"  âš¡ Throughput: {summary['throughput']:.1f} guias/s")
        print(f"  âš¡ ProjeÃ§Ã£o: {throughput_per_hour:.0f} guias/hora")
        print(f"  ğŸ’¾ MemÃ³ria: {mem_start:.0f} MB â†’ {mem_end:.0f} MB (Î”{mem_delta:+.0f} MB)")
        
        # AsserÃ§Ãµes
        assert duration < 180, f"100 guias demoraram {duration:.1f}s (limite: 180s)"
        assert summary['success'] >= 95, f"Taxa de sucesso baixa: {summary['success']}/100"
        assert mem_end < 2048, f"Uso de memÃ³ria alto: {mem_end:.0f} MB (limite: 2GB)"
    
    def test_500_guias_stress(self, rule_engine, tmp_path):
        """
        Stress test com 500 guias.
        
        Meta: < 15 minutos, < 3GB RAM
        """
        from src.business.processing.safe_batch_processor import process_batch
        
        # Gerar XMLs
        print("\nğŸ”§ Gerando 500 XMLs...")
        files = generate_test_batch(
            count=500,
            output_dir=str(tmp_path / "batch_500"),
            error_rate=0.05  # 5% com erros
        )
        
        mem_start = get_memory_usage_mb()
        
        # Processar
        print("\nğŸš€ Processando lote de 500...")
        start = time.time()
        summary = process_batch(files, rule_engine)
        duration = time.time() - start
        
        mem_end = get_memory_usage_mb()
        mem_delta = mem_end - mem_start
        throughput_per_hour = (summary['success'] / duration) * 3600
        
        # RelatÃ³rio
        print(f"\nğŸ“Š RESULTADOS - 500 Guias:")
        print(f"  âœ… Sucesso: {summary['success']}/{summary['total']}")
        print(f"  âŒ Erros: {summary['errors']}")
        print(f"  â±ï¸  Tempo: {duration:.1f}s ({duration/60:.1f} min)")
        print(f"  âš¡ Throughput: {summary['throughput']:.1f} guias/s")
        print(f"  âš¡ ProjeÃ§Ã£o: {throughput_per_hour:.0f} guias/hora")
        print(f"  ğŸ’¾ MemÃ³ria: {mem_start:.0f} MB â†’ {mem_end:.0f} MB (Î”{mem_delta:+.0f} MB)")
        
        # AsserÃ§Ãµes
        assert duration < 900, f"500 guias demoraram {duration/60:.1f}min (limite: 15min)"
        assert summary['success'] >= 450, f"Muitos erros: {summary['errors']}"
        assert mem_end < 3072, f"MemÃ³ria alta: {mem_end:.0f} MB (limite: 3GB)"
        assert throughput_per_hour > 500, f"Throughput baixo: {throughput_per_hour:.0f}/hora"
    
    def test_1000_guias_full_stress(self, rule_engine, tmp_path):
        """
        Stress test completo com 1000 guias.
        
        Meta: < 30 minutos, < 4GB RAM, > 500 guias/hora
        """
        from src.business.processing.safe_batch_processor import process_batch
        
        # Gerar XMLs
        print("\nğŸ”§ Gerando 1000 XMLs...")
        files = generate_test_batch(
            count=1000,
            output_dir=str(tmp_path / "batch_1000"),
            error_rate=0.10  # 10% com erros
        )
        
        mem_start = get_memory_usage_mb()
        print(f"ğŸ’¾ MemÃ³ria inicial: {mem_start:.0f} MB")
        
        # Processar
        print("\nğŸš€ Processando lote de 1000 guias...")
        print("   (Isso pode demorar alguns minutos...)")
        start = time.time()
        summary = process_batch(files, rule_engine, max_errors=200)
        duration = time.time() - start
        
        mem_end = get_memory_usage_mb()
        mem_delta = mem_end - mem_start
        throughput_per_hour = (summary['success'] / duration) * 3600
        
        # RelatÃ³rio completo
        print(f"\n" + "="*60)
        print(f"ğŸ“Š RESULTADOS FINAIS - 1000 Guias STRESS TEST")
        print(f"="*60)
        print(f"  ğŸ“„ Total de arquivos: {summary['total']}")
        print(f"  âœ… Processados com sucesso: {summary['success']} ({summary['success']/summary['total']*100:.1f}%)")
        print(f"  âŒ Erros: {summary['errors']} ({summary['errors']/summary['total']*100:.1f}%)")
        print(f"  â±ï¸  Tempo total: {duration:.1f}s ({duration/60:.1f} min)")
        print(f"  âš¡ Throughput mÃ©dio: {summary['throughput']:.2f} guias/segundo")
        print(f"  âš¡ ProjeÃ§Ã£o horÃ¡ria: {throughput_per_hour:.0f} guias/hora")
        print(f"  ğŸ’¾ MemÃ³ria inicial: {mem_start:.0f} MB")
        print(f"  ğŸ’¾ MemÃ³ria final: {mem_end:.0f} MB")
        print(f"  ğŸ’¾ Delta memÃ³ria: {mem_delta:+.0f} MB")
        print(f"="*60)
        
        # AsserÃ§Ãµes crÃ­ticas
        assert duration < 1800, f"1000 guias demoraram {duration/60:.1f}min (limite: 30min)"
        assert summary['success'] >= 850, f"Taxa de sucesso muito baixa: {summary['success']}/1000"
        assert mem_end < 4096, f"Uso de memÃ³ria excessivo: {mem_end:.0f} MB (limite: 4GB)"
        assert throughput_per_hour > 500, f"Throughput insuficiente: {throughput_per_hour:.0f}/hora (meta: >500)"
        
        # ValidaÃ§Ãµes adicionais
        assert mem_delta < 2048, f"Memory leak possÃ­vel: Î”{mem_delta:.0f} MB"
        
        print("\nâœ… STRESS TEST PASSOU EM TODOS OS CRITÃ‰RIOS!")


@pytest.mark.slow
class TestMemoryStability:
    """Testes de estabilidade de memÃ³ria"""
    
    def test_no_memory_leak_repetido(self, rule_engine, tmp_path):
        """
        Testa que nÃ£o hÃ¡ memory leak processando mÃºltiplos lotes.
        
        Processa 3 lotes de 50 guias e verifica memÃ³ria estÃ¡vel.
        """
        from src.business.processing.safe_batch_processor import process_batch
        
        mem_samples = []
        
        for batch_num in range(3):
            # Gerar novo lote
            files = generate_test_batch(
                count=50,
                output_dir=str(tmp_path / f"batch_{batch_num}"),
                prefix=f"batch{batch_num}"
            )
            
            # Processar
            summary = process_batch(files, rule_engine)
            
            # Medir memÃ³ria
            mem_current = get_memory_usage_mb()
            mem_samples.append(mem_current)
            
            print(f"\n  Lote {batch_num+1}: {mem_current:.0f} MB")
        
        # Verificar que memÃ³ria nÃ£o cresce descontroladamente
        mem_growth = mem_samples[-1] - mem_samples[0]
        print(f"\nğŸ’¾ Crescimento de memÃ³ria: {mem_growth:+.0f} MB")
        
        # MemÃ³ria nÃ£o deve crescer mais que 500MB apÃ³s 3 lotes
        assert mem_growth < 500, f"PossÃ­vel memory leak: +{mem_growth:.0f} MB"
